<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.45">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Introduction to Brain-Computer Interfaces â€“ SURGE NeuroTech Club</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../images/logos/logo_favicon_transparent.png" rel="icon" type="image/png">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="dark">
<link href="../../../site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="../../../site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": true,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../../styles.scss">
<meta property="og:title" content="SURGE NeuroTech Club - Introduction to Brain-Computer Interfaces">
<meta property="og:description" content="This tutorial will teach you about the basics of what Brain-Computer Interfaces are, and how they work!">
<meta property="og:image" content="images/intro_to_bci.webp">
<meta property="og:site_name" content="SURGE NeuroTech Club">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../images/logos/logo_transparent.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">SURGE NeuroTech Club</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../docs/tutorials/index.html"> 
<span class="menu-text">Get Started</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../who_we_are.html"> 
<span class="menu-text">Who We Are</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/orgs/SURGE-NeuroTech-Club/repositories" target="_blank"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text">GitHub</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/orgs/SURGE-NeuroTech-Club" target="_blank"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#what-is-a-brain-computer-interface-bci" id="toc-what-is-a-brain-computer-interface-bci" class="nav-link active" data-scroll-target="#what-is-a-brain-computer-interface-bci">What is a Brain-Computer Interface (BCI)?</a></li>
  <li><a href="#how-does-a-bci-work" id="toc-how-does-a-bci-work" class="nav-link" data-scroll-target="#how-does-a-bci-work">How Does a BCI Work?</a>
  <ul class="collapse">
  <li><a href="#the-brain-and-its-signals" id="toc-the-brain-and-its-signals" class="nav-link" data-scroll-target="#the-brain-and-its-signals">The Brain and Its Signals</a></li>
  <li><a href="#producing-and-reading-brain-signals" id="toc-producing-and-reading-brain-signals" class="nav-link" data-scroll-target="#producing-and-reading-brain-signals">Producing and Reading Brain Signals</a></li>
  <li><a href="#translating-thoughts-into-action" id="toc-translating-thoughts-into-action" class="nav-link" data-scroll-target="#translating-thoughts-into-action">Translating Thoughts into Action</a></li>
  </ul></li>
  <li><a href="#two-common-neural-responses-used-for-bci" id="toc-two-common-neural-responses-used-for-bci" class="nav-link" data-scroll-target="#two-common-neural-responses-used-for-bci">Two Common Neural Responses Used for BCI</a>
  <ul class="collapse">
  <li><a href="#event-related-potentials-erps" id="toc-event-related-potentials-erps" class="nav-link" data-scroll-target="#event-related-potentials-erps">Event-Related Potentials (ERPs)</a></li>
  <li><a href="#steady-state-visual-evoked-potentials-ssveps" id="toc-steady-state-visual-evoked-potentials-ssveps" class="nav-link" data-scroll-target="#steady-state-visual-evoked-potentials-ssveps">Steady-State Visual Evoked Potentials (SSVEPs)</a></li>
  <li><a href="#comparison-and-considerations" id="toc-comparison-and-considerations" class="nav-link" data-scroll-target="#comparison-and-considerations">Comparison and Considerations</a></li>
  <li><a href="#note-on-hybrid-bcis" id="toc-note-on-hybrid-bcis" class="nav-link" data-scroll-target="#note-on-hybrid-bcis">Note on Hybrid BCIs</a></li>
  </ul></li>
  <li><a href="#applications-of-bcis" id="toc-applications-of-bcis" class="nav-link" data-scroll-target="#applications-of-bcis">Applications of BCIs</a></li>
  <li><a href="#the-future-of-bcis" id="toc-the-future-of-bcis" class="nav-link" data-scroll-target="#the-future-of-bcis">The Future of BCIs</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  <li><a href="#further-reading" id="toc-further-reading" class="nav-link" data-scroll-target="#further-reading">Further Reading</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Introduction to Brain-Computer Interfaces</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="block-title">Abstract</div>
    This tutorial will teach you about the basics of what Brain-Computer Interfaces are, and how they work!
  </div>
</div>


</header>


<section id="what-is-a-brain-computer-interface-bci" class="level2">
<h2 class="anchored" data-anchor-id="what-is-a-brain-computer-interface-bci">What is a Brain-Computer Interface (BCI)?</h2>
<p>A Brain-Computer Interface (BCI) enables communication between the brain and an external device, such as a computer or robotic arm, without physical movement. BCIs allow users to control devices using their thoughts.</p>
</section>
<section id="how-does-a-bci-work" class="level2">
<h2 class="anchored" data-anchor-id="how-does-a-bci-work">How Does a BCI Work?</h2>
<section id="the-brain-and-its-signals" class="level3">
<h3 class="anchored" data-anchor-id="the-brain-and-its-signals">The Brain and Its Signals</h3>
<p>The brain is composed of billions of neurons that communicate through electrical signals. BCIs detect and interpret these signals, often using electroencephalography (EEG), which measures electrical activity through the scalp.</p>
<details>
<summary>
<span class="dropdown1"> Learn More about Neurons and Brain Signals </span>
</summary>
<p><br></p>
<p>Neurons are specialized cells that transmit information throughout the nervous system. They communicate via electrical impulses and chemical signals. Each neuron consists of a cell body, dendrites, and an axon. Dendrites receive incoming signals, while the axon transmits signals to other neurons.</p>
<p>Neurons generate action potentials, which are brief electrical impulses resulting from changes in membrane potential. These action potentials travel along the axon to the synapse, where neurotransmitters are released to signal adjacent neurons.</p>
EEG measures the synchronous activity of neurons, primarily in the cortex. This activity results in detectable electrical signals on the scalp, representing the brainâ€™s response to stimuli and cognitive processes.
</details>
</section>
<section id="producing-and-reading-brain-signals" class="level3">
<h3 class="anchored" data-anchor-id="producing-and-reading-brain-signals">Producing and Reading Brain Signals</h3>
<p>EEG signals arise from the synchronized activity of cortical pyramidal neurons when users focus on specific stimuli. BCI systems use machine learning algorithms to learn and interpret brain signals into commands.</p>
<details>
<summary>
<span class="dropdown1"> Understanding Electric Dipoles and EEG Detection </span>
</summary>
<p><br></p>
<p>Pyramidal neurons in the cortex are key contributors to EEG signals. These neurons have long apical dendrites oriented perpendicularly to the cortical surface, forming electric dipoles when they fire.</p>
<p>The combined electric fields of many neurons create measurable potentials on the scalp. EEG electrodes placed on the scalp detect these potentials, recording voltage fluctuations over time.</p>
Machine learning algorithms process the EEG data, identifying patterns associated with specific mental states or intentions - such as those arising from attending to a specific stimulus. This enables translation of brain activity into actionable commands for BCIs.
</details>
</section>
<section id="translating-thoughts-into-action" class="level3">
<h3 class="anchored" data-anchor-id="translating-thoughts-into-action">Translating Thoughts into Action</h3>
<p>Machine learning algorithms distinguish brain signals generated by focusing on specific stimuli from background noise, translating them into commands for device control. This enables users to perform tasks like moving a cursor, playing a game, or controlling a robotic arm solely through thought.</p>
<details>
<summary>
<span class="dropdown1"> Exploring Machine Learning in BCIs </span>
</summary>
<p>Machine learning algorithms in BCIs analyze EEG data to identify patterns (like event-related potentials or steady-state visually-evoked potentials) corresponding to user intentions (such as attending to a certain stimulus). These algorithms are trained on labeled datasets to distinguish between when random noise and when the user is attending a stimulus.</p>
<p>The most common technique is supervised learning, where models learn from labeled examples. Other techniques can be successfully used such as unsupervised learning, which identifies hidden patterns without explicit labels, and deep learning, a subset of machine learning, employs neural networks to extract complex features from EEG signals.</p>
<p>By continuously adapting to user inputs, machine learning enhances the accuracy and responsiveness of BCIs, enabling seamless interaction between the brain and external devices. <br></p>
</details>
</section>
</section>
<section id="two-common-neural-responses-used-for-bci" class="level2">
<h2 class="anchored" data-anchor-id="two-common-neural-responses-used-for-bci">Two Common Neural Responses Used for BCI</h2>
<section id="event-related-potentials-erps" class="level3">
<h3 class="anchored" data-anchor-id="event-related-potentials-erps">Event-Related Potentials (ERPs)</h3>
<p>ERPs are brain responses time-locked to specific events. They consist of components like the commonly-used P300, which occur about 300 milliseconds after an infrequent or important stimulus. In ERP-based BCIs, users focus on stimuli, and the system detects the P300 responses to determine which stimulus the user is looking at, and therefore which command to execute.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ERPs_new.png" class="img-fluid figure-img" alt="Tamara Bonaci, CC BY-ND" width="300"></p>
<figcaption>Example Event-Related Potentials - Tamara Bonaci, CC BY-ND</figcaption>
</figure>
</div>
<details>
<summary>
<span class="dropdown1"> Diving into ERP Components and Their Significance </span>
</summary>
<p>ERP components are labeled based on their polarity (positive or negative) and timing. Key components include:</p>
<ul>
<li><strong>P300:</strong> A positive deflection occurring around 300 milliseconds after an infrequent or significant stimulus. In BCIs, the P300 is used to detect when a user is focusing on a particular stimulus, such as a specific letter in a matrix. The system then translates this detection into a command, enabling the user to select that letter or perform an action.</li>
<li><strong>N200:</strong> A negative deflection associated with response inhibition and conflict detection. In BCIs, the N200 can be used to monitor error detection or user responses to conflicting stimuli, which can be integrated into more sophisticated control systems.</li>
<li><strong>N400:</strong> Related to language processing and semantic incongruence. While less commonly used in BCIs, the N400 could assist in applications involving language or communication tasks by detecting how users process and respond to language-based stimuli.</li>
</ul>
ERPs provide insights into cognitive processes and brain responses, making them valuable for understanding attention, perception, and decision-making. <br>
</details>
</section>
<section id="steady-state-visual-evoked-potentials-ssveps" class="level3">
<h3 class="anchored" data-anchor-id="steady-state-visual-evoked-potentials-ssveps">Steady-State Visual Evoked Potentials (SSVEPs)</h3>
<p>SSVEPs are responses to flickering visual stimuli, causing detectible brain waves at the same frequency. In SSVEP-based BCIs, users focus on a flickering stimulus to synchronize brain activity with its frequency, allowing for the machine learning algorithm to determine which stimulus the user is focused on, and then execute the corresponding command.</p>
<details>
<summary>
<span class="dropdown1"> Delving into SSVEPs and Frequency Analysis </span>
</summary>
<p>SSVEPs are generated when the visual cortex responds to stimuli flickering at specific frequencies. The brainâ€™s response frequency matches the stimulus frequency, enabling reliable detection with EEG.</p>
<p>In SSVEP-based BCIs, users focus on one of several flickering stimuli, each associated with a distinct command. The system identifies the frequency of the brainâ€™s response to determine user intent. (For example, if the user attends to a stimulus flickering at 10 Hz, the resulting EEG signals would show a 10 Hz oscillation, and the machine learning algorithm would perform the command corresponding to the stimulus flickering at 10 Hz)</p>
Frequency analysis involves decomposing EEG signals into their frequency components. Techniques such as Fourier Transform and Wavelet Transform help isolate SSVEP frequencies for accurate interpretation. <br>
</details>
</section>
<section id="comparison-and-considerations" class="level3">
<h3 class="anchored" data-anchor-id="comparison-and-considerations">Comparison and Considerations</h3>
<ul>
<li><strong>Speed and Accuracy:</strong> SSVEP-based BCIs generally offer faster and more accurate responses due to direct frequency matching.</li>
<li><strong>User Comfort:</strong> ERP-based systems may be less visually demanding, as SSVEPs require focus on flickering stimuli, which can cause fatigue.</li>
<li><strong>Signal Processing:</strong> Both require advanced techniques to interpret user intentions from EEG data.</li>
</ul>
</section>
<section id="note-on-hybrid-bcis" class="level3">
<h3 class="anchored" data-anchor-id="note-on-hybrid-bcis">Note on Hybrid BCIs</h3>
<p>Hybrid BCIs combine multiple neural responses, such as ERPs and SSVEPs, to enhance the performance and versatility of the system. By leveraging the strengths of different neural signals, hybrid BCIs can provide more robust and reliable control, especially in complex or dynamic environments.</p>
<p><strong>How Hybrid BCIs Work:</strong> - <strong>Integration of Multiple Signals:</strong> Hybrid BCIs simultaneously monitor different types of brain signals, such as combining the time-locked precision of ERPs with the continuous frequency information from SSVEPs. This integration allows the system to cross-validate user intentions, improving accuracy. - <strong>Increased Command Options:</strong> By using both ERPs and SSVEPs, hybrid BCIs can offer a wider range of commands or actions. For example, an ERP might be used to select a menu item, while an SSVEP could determine how to interact with it. - <strong>Enhanced Adaptability:</strong> Hybrid BCIs can adapt to varying user states or environmental conditions. If one signal type becomes less reliable (e.g., if a user becomes fatigued and SSVEP detection declines), the system can rely more heavily on the other signal type.</p>
<details>
<summary>
<span class="dropdown1"> Advantages and Applications of Hybrid BCIs </span>
</summary>
<strong>Advantages:</strong> - <strong>Improved Accuracy:</strong> The combination of multiple neural signals reduces the likelihood of errors by cross-referencing different types of brain activity. - <strong>Greater Flexibility:</strong> Users can perform a broader range of actions, as the system can interpret more diverse types of commands. - <strong>Resilience:</strong> Hybrid BCIs can maintain functionality even if one type of signal is compromised, making them more reliable in real-world applications. <br>
</details>
<p>Hybrid BCIs represent an exciting frontier in brain-computer interface technology, combining the best of multiple approaches to create more effective and user-friendly systems. As research and development continue, hybrid BCIs are likely to become increasingly prominent in both clinical and non-clinical applications.</p>
</section>
</section>
<section id="applications-of-bcis" class="level2">
<h2 class="anchored" data-anchor-id="applications-of-bcis">Applications of BCIs</h2>
<p>BCIs have transformative potential across fields:</p>
<ul>
<li><strong>Medical:</strong> Helping individuals with disabilities control wheelchairs or prosthetic limbs.</li>
<li><strong>Communication:</strong> Allowing those unable to speak to convert thoughts into text or speech.</li>
<li><strong>Gaming and Entertainment:</strong> Creating immersive experiences controlled by thought.</li>
<li><strong>Research and Exploration:</strong> Studying brain functions and developing neurological treatments.</li>
</ul>
<details>
<summary>
<span class="dropdown1"> Exploring BCI Applications in More Detail </span>
</summary>
<ul>
<li><strong>Medical Applications:</strong> BCIs restore independence for individuals with mobility impairments, enabling them to control assistive devices through thought alone. For example, BCIs can be integrated with robotic prosthetics to facilitate movement for amputees or individuals with paralysis.</li>
<li><strong>Communication:</strong> BCIs enable individuals with communication disorders to express themselves by converting brain signals into text or speech, enhancing social interaction and quality of life.</li>
<li><strong>Gaming and Entertainment:</strong> BCIs offer unique gaming experiences, where players control in-game actions using their thoughts, creating a more immersive and interactive environment.</li>
<li><strong>Research:</strong> BCIs facilitate research into brain function and cognitive processes, providing insights into neural mechanisms underlying behavior and aiding the development of treatments for neurological disorders. <br></li>
</ul>
</details>
</section>
<section id="the-future-of-bcis" class="level2">
<h2 class="anchored" data-anchor-id="the-future-of-bcis">The Future of BCIs</h2>
<p>BCI technology is evolving rapidly, with ongoing research aiming to make systems more accessible and user-friendly, expanding their impact on how we interact with technology.</p>
<details>
<summary>
<span class="dropdown1"> Innovations and Future Directions in BCIs </span>
</summary>
<ul>
<li><strong>Improved Accessibility:</strong> Researchers are working on developing affordable and easy-to-use BCI systems, making them accessible to a wider population.</li>
<li><strong>Enhanced Signal Quality:</strong> Advances in signal processing and electrode technology aim to improve the quality and reliability of EEG signals, enhancing BCI performance.</li>
<li><strong>Integration with AI:</strong> Combining BCIs with artificial intelligence allows for more sophisticated interpretation of brain signals, improving the accuracy and speed of communication and control.</li>
<li><strong>Wearable BCIs:</strong> Future BCIs may be integrated into wearable devices, offering seamless and unobtrusive interaction with technology in everyday life. <br></li>
</ul>
</details>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Brain-Computer Interfaces merge neuroscience and technology, enabling direct communication between the brain and devices. They have the potential to revolutionize various fields, making the world more inclusive and innovative.</p>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<p>General Neuroscience:</p>
<ul>
<li><a href="https://uk.sagepub.com/en-gb/eur/research-methods-for-cognitive-neuroscience/book242924">Research Methods in Cognitive Neuroscience [Book] - Dr.&nbsp;Aaron Newman</a></li>
</ul>
<p>General BCI:</p>
<ul>
<li><a href="https://doi.org/10.3389/fnsys.2021.578875">Progress in Brain Computer Interface: Challenges and Opportunities - Saha et al., 2017</a></li>
<li><a href="https://doi.org/10.3389/fnbot.2020.00025">Current Status, Challenges, and Possible Solutions of EEG-Based Brain-Computer Interface: A Comprehensive Review - Rashid et al., 2020</a></li>
<li><a href="https://doi.org/10.1109/JSEN.2020.3017491">Data Analytics in Steady-State Visual Evoked Potential-Based Brainâ€“Computer Interface: A Review - Zhang et al., 2021</a></li>
<li><a href="https://doi.org/10.1080/10447318.2022.2093445">Hybrid brainâ€“computer interface spellers: A walkthrough recent advances in signal processing methods and challenges. International Journal of Humanâ€“Computer Interaction - Chugh, N. &amp; Aggarwal, S., 2022</a></li>
</ul>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Copyright 2024, SURGE Innovation
  </li>  
</ul>
    </div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="../../../site_info.html">
<p>About Site</p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../../contact_us.html">
<p>Contact Us</p>
</a>
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
<p>This website is built with <i class="fa-solid fa-heart" title="a heart" aria-label="heart"></i>, <a href="https://github.com/SURGE-NeuroTech-Club/SURGE-NeuroTech-Club.github.io" target="_blank"><i class="fa-brands fa-github" title="GitHub octocat logo" aria-label="github"></i></a>, <a href="https://www.r-project.org/about.html" target="_blank"><i class="fa-brands fa-r-project" title="R Project" aria-label="r-project"></i></a> and <a href="https://quarto.org/" target="_blank">Quarto</a></p>
</div>
  </div>
</footer>




</body></html>