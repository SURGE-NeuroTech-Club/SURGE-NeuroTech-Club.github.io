---
title: "A Beginner's Guide to Machine Learning Concepts and Applications"
abstract: "This tutorial introduces the fundamentals of machine learning, covering key concepts such as supervised and unsupervised learning, data labeling, and model evaluation."
image: images/intro-to-ml.webp
format: 
    html:
        toc: true
        link-external-newwindow: true
---

```{python}
#| label: Python Setup
#| include: false
#| warning: false
#| messages: false

# Data manipulation and visualization libraries
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px

# Color map for plots
from matplotlib.colors import ListedColormap

# ML and data handling
from sklearn.datasets import load_iris
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier
from sklearn.gaussian_process import GaussianProcessClassifier
from sklearn.gaussian_process.kernels import RBF
from sklearn.decomposition import PCA
from sklearn.inspection import DecisionBoundaryDisplay
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Additional plotting functionality
from mlxtend.plotting import plot_decision_regions

```

## What is Machine Learning?

Machine learning is a subset of artificial intelligence where computers use data to identify patterns and make predictions. These models improve over time by learning from new data and experiences.

Machine learning algorithms work by identifying patterns in the data, specifically between the independent variables (features, often represented as X) and the dependent variables (targets, often represented as Y). These patterns enable the model to make predictions or classifications based on new, unseen data.

## Labeled & Unlabeled Data

Before we get into machine learning, we need to talk about data. Data is the foundation of all machine learning—without it, we wouldn't be able to train the models! There are two broad categories of data used in machine learning: labeled and unlabeled data.

Labeled data contains both the input and the corresponding correct output/target or dependent measure. In this example, we can see two types of labeled data—one labeled with "cat/dog" and another labeled with "weight." In each case, the model would be trained to predict whether the input was a cat or a dog, or to estimate the weight, depending on the label provided. Unlabeled data only contains the input, leaving the model to identify patterns without guidance.

![](images/labelled-unlabeled.png){width="60%" fig-align="center"}

## Two Category of Machine Learning

Machine learning can be broadly divided into two primary categories: supervised and unsupervised learning. Each approach has its own strengths and limitations, making them suitable for different types of tasks.

::::::: columns
:::: {.column width="50%"}
::: {style="text-align: center;"}
#### Supervised Learning
:::
-   Uses [labeled]{.highlight1} training data
-   Majority of machine learning applications
-   Commonly used for tasks like [classification]{.highligh1} and regression
::::

:::: {.column width="50%"}
::: {style="text-align: center;"}
#### Unsupervised Learning
:::
-   Uses [unlabeled]{.highlight1} training data
-   Less common but powerful for exploratory analysis
-   Often used for clustering, content personalization, and dimensionality reduction
::::
:::::::

::: {style="text-align: center; text-decoration: underline;"}
### Supervised Machine Learning 
:::

Supervised machine learning involves training models on labeled data, where the goal is often to make predictions or classifications based on new, unseen data.

::::::: columns
:::: {.column width="50%"}
::: {style="text-align: center;"}
#### Pros
:::
-   High accuracy
    -   Ability to learn from known examples
-   Excellent predictive power
    -   Effective at classifying new data based on historical patterns
::::

:::: {.column width="50%"}
::: {style="text-align: center;"}
#### Cons
:::
-   Requires labeled data
    -   Time-consuming and expensive to obtain
-   Risk of overfitting
    -   Models may become too tailored to the training data
::::
:::::::

[Common Algorithms: Linear/Logistic Regression, Support Vector Machines, Decision Trees, K-nearest neighbours]{.footer-font}

::: {style="text-align: center; text-decoration: underline;"}
### Unsupervised Machine Learning
:::

Unsupervised learning involves using algorithms to analyze and cluster unlabeled data, discovering hidden patterns without predefined labels.

::::::: columns
:::: {.column width="50%"}
::: {style="text-align: center;"}
#### Pros
:::
- Powerful for data exploration
  - Uncovers hidden structures and patterns in data
- Useful for dimensionality reduction
  - Simplifies complex datasets, making them easier to visualize and interpret
::::

:::: {.column width="50%"}
::: {style="text-align: center;"}
#### Cons
:::
- Lower interpretability
  - Patterns and structures are harder to understand without labels
- Challenging model evaluation
  - Difficult to assess model quality without clear metrics
::::
:::::::

[Common Algorithms: Principal Component Analysis (PCA), K-Means Clustering, t-Distributed Stochastic Neighbor Embedding (t-SNE)]{.footer-font}

# How Does Machine Learning Work?

The [UC Berkeley School of Information](https://ischoolonline.berkeley.edu/blog/what-is-machine-learning/) has defined 3 components of most supervised machine learning algorithms.

## 1. A Decision Process:

In general, machine learning algorithms are used to make a [prediction or classification]{.highlight1}. Based on some input data. The algorithm will produce an [estimate about a pattern]{.highlight1} in the data.

## 2. An Error Function:

An error function [evaluates the prediction]{.highlight1} of the model. If there are known examples, an error function can make a comparison to assess the performance of the model.

## 3. A Model Optimization Process:

When the model does a good job of matching the training data, it tweaks its settings to get better at classifying the actual data. This process of [“evaluate and optimize”]{.highlight1} happens over and over again, allowing the model to adjust itself automatically.

# Mini Tutorial with the Iris Dataset!

Let's dive into a hands-on example using the famous Iris dataset. This classic dataset is perfect for illustrating basic machine learning concepts.

## Human Classification Exercise

Before we get into the technical details, let's start with a quick exercise. A while ago, I was hiking in Duncan's Cove and came across some irises. I used an app called "Seek," which leverages machine learning to identify species using your phone's camera. Curious to see how well it worked, I tested it on an iris I found. But before I reveal the app's result, I want you to take a look for yourself!

### What do you think?

Take a moment to compare the iris on the left with the Northern Blue Flag iris (middle) and the Beach Head iris (right). Which one do you think it resembles more? Consider what influenced your decision—was it the shape, color, or perhaps some other feature?

::::: {layout="[1,1,1]"}
![My Picture from Duncan's Cove](images/duncans_iris_zoom.jpg){width=300 height=250}

!["Northern Blue Flag" - Versicolor](images/northern%20blue%20flag%20(Iris%20versicolor)_files2.jpg){width=300 height=250}

!["Beach-Head" - Setosa](images/Beach-head%20Iris%20(iris%20setosa)2.jpeg){width=300 height=250}
:::::


### Misclassification?

Interestingly, the Seek App identified the iris I found as a Versicolor, but two experts later claimed it was a Setosa. This discrepancy highlights a critical aspect of machine learning: the selection of features.

![](images/inaturalist_pic.PNG){width="60%" fig-align="center"}

## Choosing (the right) Features is Important!

A [Feature]{.highlight1} is "an individual measurable property or characteristic of a phenomenon".[^1] In the context of machine learning, selecting the right features is critical to the success of your model.

Using informative, discriminative, and independent features is essential for building effective classification algorithms. The features you choose can significantly influence the model’s ability to learn accurately from the data and make reliable predictions. In the case of our iris example, perhaps the app's algorithm relied on certain features that led it to misclassify the species.

[^1]: [Bishop, Christopher (2006). *Pattern recognition and machine learning*](https://en.wikipedia.org/wiki/Feature_(machine_learning)#cite_note-ml-1)

## The Iris Dataset

The Iris dataset is a classic example used in machine learning, containing three types of iris flowers: Setosa, Versicolor, and Virginica.

![](images/iris_ex.png){width="85%" fig-align="center"}

The species of each iris can be determined by a combination of features, specifically the [petal and sepal width and length]{.highlight1}.

## Taking Another Look

Given the features we’ve discussed, do you think the Seek AI might have relied on different features or interpreted them differently, leading to the incorrect classification?

::::: {layout="[1,1,1]"}
![My Picture from Duncan's Cove](images/duncans_iris_zoom.jpg){width=300 height=250}

!["Northern Blue Flag" - Versicolor](images/northern%20blue%20flag%20(Iris%20versicolor)_files2.jpg){width=300 height=250}

!["Beach-Head" - Setosa](images/Beach-head%20Iris%20(iris%20setosa)2.jpeg){width=300 height=250}
:::::

## Let's Explore the Dataset!

To better understand how machine learning models work, let’s take a closer look at the Iris dataset.

:::::: columns
::: {.column width="50%"}
```{python}
#| label: Iris-dataset
#| echo: false
#| code-fold: true
#| code-summary: "Show the code"

data = px.data.iris()
columns_df = pd.DataFrame(data.iloc[:, 0:5].columns, columns=['Variables'])

columns_df = pd.concat([columns_df, pd.DataFrame({'Variables': [f'# Observations: {len(data)}']})], ignore_index=True)

columns_df
```
:::

:::: {.column width="50%"}
::: {style="font-size: 30px;"}
-   4 Features (Independent Variables)
-   150 Total Observations
    -   50 of each Iris Type
-   Excellent sample to demonstrate machine learning!
:::

![](images/sepal-petal.png){width="45%" fig-align="center"}
::::
::::::

## Visualizing the Raw Data

To start, let’s visualize the raw data from the Iris dataset to better understand the relationships between different features.

```{python}
#| label: CorrPlot
#| fig-align: 'center'
#| fig-width: 6
#| fig-height: 4
#| code-fold: true
#| code-summary: "Show the code"

plt.style.use("dark_background")

# Making a correlation plot of all variables except 'Id'
corr_plot = sns.pairplot(data.iloc[:, 0:5], kind="scatter", hue="species", markers=["o", "s", "D"], palette="Set2", plot_kws={'alpha': 0.7})

sns.move_legend(corr_plot, "lower center",
    bbox_to_anchor=(0.5, 1), ncol=3, title=None, frameon=False
)

# Resize to fit
# corr_plot.fig.set_size_inches(12, 5.5)

# Show the plot
corr_plot
```

This plot offers a clear visualization of how different features are interrelated across the three iris species. Notice how, in various panels, each species tends to form its own distinct grouping, highlighting the separability of the data based on the selected features.

## Reducing Dimentionality {.smaller}

Dimensionality reduction techniques, like Principal Component Analysis (PCA), help us simplify complex datasets. By translating our 4-dimensional data into two dimensions, we can better visualize the differences between species.

```{python}
#| fig-align: center

plt.figure(figsize=(12, 6))

df = px.data.iris()
X = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]

pca = PCA(n_components=2)
components = pca.fit_transform(X)

# Create a DataFrame with the PCA results
pca_df = pd.DataFrame(data=components, columns=['PCA1', 'PCA2'])
pca_df['species'] = df['species']

# Plot the PCA results
pca2d = sns.scatterplot(data=pca_df, x='PCA1', y='PCA2', hue='species', palette="Set2")
```

## Seperating Our Dependent and Independent Variables

Next, let’s separate our dataset into independent (X) and dependent (y) variables. This is a crucial step before training our model.

```{python}
#| label: Ind-Dep1
#| panel: center
#| echo: true
#| class: output-style
#| code-line-numbers: "1,2"

X = data.drop(['species_id', 'species'], axis=1)
y = data['species']
```

```{python}
#| label: Ind-Dep2
#| echo: false
#| class: output-style3

print(f'The feature (X/independent) variables are of shape: {X.shape}')
print(f'The target (y/dependent) variables are of shape: {y.shape}')
```

::::: columns
::: {.column width="50%"}
```{python}
#| label: Ind-Dep3
#| panel: center
#| echo: false
#| class: output-style2

columns_df2 = pd.DataFrame(X.columns, columns=['Independent Vars'])

# columns_df2 = pd.concat([columns_df, pd.DataFrame({'Variables': [f'# Observations: {len(data)}']})], ignore_index=True)

columns_df2
```
:::

::: {.column width="50%"}
```{python}
#| label: Ind-Dep4
#| panel: center
#| echo: false
#| class: output-style2

y_sample = pd.DataFrame(y.sample(4))

y_sample
```
:::
:::::

## Train-Test Split

The classifier's performance can become inflated if it trains on the same data it is tested with. This is called [data-leakage.]{.highlight1}

To evaluate model performance accurately, it's essential to split the data into training and testing sets. We must split the data into [training and testing sets.]{.highlight1}

This step helps us test how well the model generalizes to [unseen data]{.highlight1}.

![](images/train-test-split-1.png){fig-align="center"}

## Making the Train-Test Split

Let’s proceed with the train-test split, keeping 30% of the data for testing and ensuring the class distribution remains consistent through stratification.

```{python}
#| label: Train-test-split1
#| echo: true

X_train, X_test, y_train, y_test = train_test_split(X, y, 
                                                        test_size=0.3,
                                                        stratify=y,
                                                        random_state=42)
```

-   **Test size**: 30% of the data is reserved for testing the model.
-   **Stratify**: Preserves the class ratios (33% of each iris species).

```{python}
#| label: Train-test-split2
#| panel: center
#| echo: false
#| class: output-style3

print(f'X_train shape is: {X_train.shape}')
print(f'y_train shape is: {y_train.shape} \n')

print(f'X_test shape is: {X_test.shape}')
print(f'y_test shape is: {y_test.shape}')
```

## Why is Stratification Important? {.smaller}

Stratification is crucial because it ensures that each class is proportionally represented in both the training and testing sets.

Without stratification, the model might over-focus on more prevalent classes, leading to [biased performance and poor accuracy on underrepresented classes]{.highlight1}.

```{python}
#| label: Stratifcation
#| echo: false
#| panel: center


# Load the Iris dataset
iris = load_iris()
X = iris.data
y = iris.target

# Perform a standard train-test split (non-stratified)
X_train_ns, X_test_ns, y_train_ns, y_test_ns = train_test_split(X, y, test_size=0.3, random_state=42)

# Perform a stratified train-test split
X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)

def plot_combined_distribution(y_train_ns, y_test_ns, y_train_s, y_test_s):
    fig, axs = plt.subplots(1, 2, figsize=(12, 5), sharey=True)
    
    # Plot for Non-Stratified Split
    labels, counts = np.unique(y_train_ns, return_counts=True)
    axs[0].bar(labels, counts, width=0.4, align='center', label='Train', color='skyblue')
    labels, counts = np.unique(y_test_ns, return_counts=True)
    axs[0].bar(labels + 0.4, counts, width=0.4, align='center', label='Test', color='orange')
    axs[0].set_title('Non-Stratified Split')
    axs[0].set_xlabel('Class')
    axs[0].set_ylabel('Count')
    axs[0].set_xticks(labels + 0.2)
    axs[0].set_xticklabels(iris.target_names)
    axs[0].legend()

    # Plot for Stratified Split
    labels, counts = np.unique(y_train_s, return_counts=True)
    axs[1].bar(labels, counts, width=0.4, align='center', label='Train', color='skyblue')
    labels, counts = np.unique(y_test_s, return_counts=True)
    axs[1].bar(labels + 0.4, counts, width=0.4, align='center', label='Test', color='orange')
    axs[1].set_title('Stratified Split')
    axs[1].set_xlabel('Class')
    axs[1].set_xticks(labels + 0.2)
    axs[1].set_xticklabels(iris.target_names)
    axs[1].legend()

    plt.tight_layout()
    plt.show()

# Call the function to plot the combined distribution
plot_combined_distribution(y_train_ns, y_test_ns, y_train_s, y_test_s)
```

## Training the Models!

Now that our data is ready, let’s train several machine learning models and evaluate their performance.

```{python}
#| label: load-data-again 
#| echo: false
#| warning: false
#| messages: false
 
iris = load_iris()
X = iris.data
y = iris.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)
```

```{python}
#| label: model-training
#| echo: true
#| code-line-numbers: "2-9|13|14|15"

# Instantiate the classifiers
classifiers = [
    SVC(kernel='linear', random_state=42),
    SVC(kernel='rbf', random_state=42),
    DecisionTreeClassifier(random_state=42),
    RandomForestClassifier(random_state=42),
    KNeighborsClassifier(),
    LogisticRegression(random_state=42, max_iter=1000)
]

# Train the classifiers
for clf in classifiers:
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"Accuracy of {clf.__class__.__name__}: {accuracy:.2f}")
```

## Visualizing Machine Learning!

Let’s visualize the decision boundaries for the trained models to see how well they differentiate between the different species.

![](images/combined_PCA_decision_boundaries_with_accuracy2.png){fig-align="center"}

## Evaluating Model Performance

Evaluation metrics are crucial for understanding how well your model is performing. The most commonly used metric is [Accuracy]{.highlight1}.

$$
\text{Accuracy} = \frac{\text{Number of Correct Predictions}}{\text{Total Number of Predictions}}
$$

While accuracy is useful, it’s not always the best metric, especially in cases of imbalanced classes.

## Evaluating Model Performance {.smaller}
$$
\scriptsize{\text{Accuracy} = \frac{\text{Number of Correct Predictions}}{\text{Total Number of Predictions}}}
$$

:::::::: columns
:::: {.column width="50%"}
![](images/Linear_SVM_CM.png)

::: {.fragment .fade-in}
45 Correct Predictions / 45 Total Prediction = 1.00
:::
::::

::::: {.column width="50%"}
::: {.fragment .fade-in}
![](images/DecisionTree_CM.png)
:::

::: {.fragment .fade-in}
43 Correct Predictions / 45 Total Prediction = 0.95
:::
:::::
::::::::

## When is Accuracy Sub-optimal? {.smaller}

In cases of [imbalanced classes]{.highlight1}, accuracy can be misleading. Let’s explore why this is the case.

::::::: columns
::: {.column width="50%"}
![](images/imbalanced-dataset2.png){fig-align="center"}
:::

::::: {.column width="50%"}
Say there are 100 observations: 80 Setosa, and 20 Versicolor.

::: {.fragment .fade-in}
If the classifier predicted 'Setosa' for all 100 observations, what would the accuracy be?

$$
\scriptsize{\text{Accuracy} = \frac{\text{Number of Correct Predictions}}{\text{Total Number of Predictions}}}
$$
:::

::: {.fragment .fade-in}
80 Correct Predictions / 100 Total Predictions = 0.80

-   Metrics like F1 score, Precision, and Recall (Sensitivity) can provide a more complete picture.
:::
:::::
:::::::

## Summary:

<br>

::: incremental
-   Labelled data (used in supervised ML) is particularly powerful for classification tasks.
-   Choosing informative features is critical to model success.
-   Train-test-split is crucial to avoid data-leakage.
-   Stratification ensures balanced class representation and avoids inflated performance metrics.
-   Accuracy is useful but not always sufficient, especially with imbalanced classes.
:::

## Thanks for Listening {.center-h2}

![](https://gifdb.com/images/high/thank-you-emoji-giving-two-thumbs-ups-6ud8p4up69m7w8tz.gif){fig-align="center"}